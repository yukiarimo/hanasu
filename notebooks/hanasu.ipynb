{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNIEiTSY08lf"
      },
      "source": [
        "# Welcome to Hanasu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4M-3d4zQTYC"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/wavs.zip', 'r') as zip_ref: zip_ref.extractall('zipfolder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GnDPtUARGji"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/hanasu/hanasu\n",
        "!pip install -r requirements.txt\n",
        "%cd /content/drive/MyDrive/vits2_pytorch-main/monotonic_align\n",
        "!python setup.py build_ext --inplace\n",
        "%cd ../\n",
        "!apt-get update && apt-get install -y espeak-ng\n",
        "!pip install phonemizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2yS6_LM1bVd"
      },
      "source": [
        "# Preprocess the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ-GhNqynpzx"
      },
      "outputs": [],
      "source": [
        "from text import preprocess_filelists\n",
        "preprocess_filelists([\"configs/Yuna/transcript-huge.txt\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fix Bugs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install librosa==0.9.1\n",
        "!pip install tensorboard==2.12.0 tensorflow==2.12.0\n",
        "!pip install matplotlib==3.7.0 # This fixes: 'FigureCanvasAgg' object has no attribute 'tostring_rgb'\n",
        "!pip install numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "directory = '/content/Yuna/wavs'\n",
        "for filename in os.listdir(directory):\n",
        "  if filename.endswith(\".mel.pt\"):\n",
        "    os.remove(os.path.join(directory, filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPPDxdW51jck"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljy_hDZCSE14"
      },
      "outputs": [],
      "source": [
        "!bash train.sh /content/Yuna/config.json 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGE29b1q1g-x"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd ../hanasu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from models import inference\n",
        "from scipy.io.wavfile import write\n",
        "import sounddevice as sd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rXuDdi44xsi"
      },
      "outputs": [],
      "source": [
        "text =\"A text view always uses exactly the amount of space it needs to display its rendered contents, but you can affect the view’s layout. For example, you can use the frame(width:height:alignment:) modifier to propose specific dimensions to the view. If the view accepts the proposal but the text doesn’t fit into the available space, the view uses a combination of wrapping, tightening, scaling, and truncation to make it fit. With a width of 100 points but no constraint on the height, a text view might wrap a long string.\"\n",
        "# Or you can read from a file:\n",
        "# with open(\"text.txt\", 'r', encoding='utf-8') as f: text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# No streaming inference\n",
        "result = inference(\n",
        "    model_path=\"/Users/yuki/Downloads/G_158000.pth\",\n",
        "    text=text,\n",
        "    config_path=\"./configs/config.json\",\n",
        "    noise_scale=0.2,\n",
        "    noise_scale_w=1.0,\n",
        "    length_scale=1.0,\n",
        "    device=\"mps\",\n",
        "    stream=False,\n",
        ")\n",
        "\n",
        "write(data=result, rate=48000, filename=\"sample_vits2.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Streaming inference\n",
        "audio_generator = inference(\n",
        "    model_path=\"/Users/yuki/Downloads/G_158000.pth\",\n",
        "    text=text,\n",
        "    config_path=\"./configs/config.json\",\n",
        "    noise_scale=0.2,\n",
        "    noise_scale_w=1.0,\n",
        "    length_scale=1.0,\n",
        "    device=\"mps\",\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "for audio_chunk in audio_generator:\n",
        "    # Play each chunk immediately as it's generated\n",
        "    sd.play(audio_chunk, samplerate=48000)\n",
        "    sd.wait()  # Wait for chunk to finish playing\n",
        "    print(f\"Played chunk of {len(audio_chunk)} samples\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "yuna",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
